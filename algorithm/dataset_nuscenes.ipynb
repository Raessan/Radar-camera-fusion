{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6505caf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import os\n",
    "import skimage.io as io\n",
    "from skimage.transform import resize\n",
    "from nuscenes.utils.geometry_utils import view_points, transform_matrix\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "from nuscenes.utils.data_classes import RadarPointCloud\n",
    "\n",
    "from plotting import draw_sample, draw_masked_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f694249",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepthDatasetNuscenes(Dataset):\n",
    "    def __init__(self, mode, dir_data, w_resized, h_resized, min_dist, max_dist, number_radar_points, augment_dist=False, augment_dist_max_subtract=4.0, augment_dist_min_scale=0.8):\n",
    "        self.mode = mode\n",
    "        self.dir_data = dir_data\n",
    "        self.w_resized = w_resized\n",
    "        self.h_resized = h_resized\n",
    "        self.min_dist = min_dist\n",
    "        self.max_dist = max_dist\n",
    "        self.number_radar_points = number_radar_points\n",
    "        self.augment_dist = augment_dist\n",
    "        self.augment_dist_max_subtract = augment_dist_max_subtract\n",
    "        self.augment_dist_min_scale = augment_dist_min_scale\n",
    "\n",
    "        if self.mode == \"train\":\n",
    "            self.sample_indices = torch.load(os.path.join(self.dir_data,'data_split.tar'))['train_sample_indices']\n",
    "        elif self.mode == \"val\":\n",
    "            self.sample_indices = torch.load(os.path.join(self.dir_data,'data_split.tar'))['val_sample_indices']\n",
    "        elif self.mode == \"test\":\n",
    "            self.sample_indices = torch.load(os.path.join(self.dir_data,'data_split.tar'))['test_sample_indices']\n",
    "        elif self.mode == \"trainval\":\n",
    "            train_sample_indices = torch.load(os.path.join(self.dir_data,'data_split.tar'))['train_sample_indices']\n",
    "            val_sample_indices = torch.load(os.path.join(self.dir_data,'data_split.tar'))['val_sample_indices']\n",
    "            self.sample_indices = train_sample_indices + val_sample_indices\n",
    "        else:\n",
    "             raise Exception(\"The mode is invalid. Possible values are train, val, test, trainval\")\n",
    "             \n",
    "    def __len__(self):\n",
    "        return len(self.sample_indices)\n",
    "    \n",
    "    def augment_pointcloud(self, points, subtract_value, scale_value):\n",
    "        \"\"\"\n",
    "        Augment the radar/lidar points by subtracting a random value from the distances.\n",
    "        \"\"\"\n",
    "        augmented_points = points.copy()\n",
    "        augmented_points[2, :] = np.maximum(augmented_points[2, :] - subtract_value, 0)\n",
    "        augmented_points[2, :] = augmented_points[2, :] * scale_value\n",
    "        return augmented_points\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        rel_depth = np.load(os.path.join(self.dir_data, \"relative_depth\", '%05d_rel_depth.npy' % self.sample_indices[idx]))\n",
    "        matrix = np.load(os.path.join(self.dir_data, \"cam_matrix\", '%05d_cam_matrix.npz' % self.sample_indices[idx]))\n",
    "        radar = np.load(os.path.join(self.dir_data, \"radar\", '%05d_radar_pc.npy' % self.sample_indices[idx]))\n",
    "        lidar = np.load(os.path.join(self.dir_data, \"lidar\", '%05d_lidar_pc.npy' % self.sample_indices[idx]))\n",
    "\n",
    "        h_original = rel_depth.shape[0]\n",
    "        w_original = rel_depth.shape[1]\n",
    "\n",
    "        self.w_nn = self.w_resized\n",
    "        self.h_nn = self.h_resized\n",
    "\n",
    "        # Update image\n",
    "        if self.w_nn == 0:\n",
    "            self.w_nn = w_original\n",
    "        if self.h_nn == 0:\n",
    "            self.h_nn = h_original\n",
    "        if self.w_nn is not w_original or self.h_nn is not h_original:\n",
    "            rel_depth = resize(rel_depth, (self.h_nn, self.w_nn), order=1, preserve_range=True, anti_aliasing=False)\n",
    "        # Revert rel_depth so it represents depth instead of inverses\n",
    "        rel_depth = 1-rel_depth\n",
    "        \n",
    "        # Update matrix\n",
    "        K = matrix['K']\n",
    "        scale_factor_w = self.w_nn/w_original\n",
    "        scale_factor_h = self.h_nn/h_original\n",
    "        K[0][0] *= scale_factor_w\n",
    "        K[1][1] *= scale_factor_h\n",
    "        K[0][2] *= scale_factor_w\n",
    "        K[1][2] *= scale_factor_h\n",
    "\n",
    "        # Boolean to know if it is radar or lidar\n",
    "        is_radar = True\n",
    "        radar_adapted = None\n",
    "        lidar_adapted = None\n",
    "        # Subtract value in case we perform augmentation\n",
    "        subtract_value = np.random.uniform(0, self.augment_dist_max_subtract)\n",
    "        scale_value = np.random.uniform(self.augment_dist_min_scale, 1.0)\n",
    "        for pc in [radar, lidar]:\n",
    "            # Grab the depths (camera frame z axis points away from the camera).\n",
    "            depths = pc[2, :]\n",
    "            # Take the actual picture (matrix multiplication with camera-matrix + renormalization).\n",
    "            points = view_points(pc, K, normalize=True)\n",
    "            # We change the third dimension (which is 1 after renormalization) to the depth\n",
    "            points[2, :] = depths\n",
    "\n",
    "            # Augment distance values\n",
    "            if self.augment_dist and self.mode == 'train':\n",
    "                points = self.augment_pointcloud(points, subtract_value, scale_value)\n",
    "                depths = points[2, :]\n",
    "\n",
    "            # Remove points that are either outside or behind the camera. Leave a margin of 1 pixel for aesthetic reasons.\n",
    "            # Also make sure points are at least 1m in front of the camera to avoid seeing the lidar points on the camera\n",
    "            # casing for non-keyframes which are slightly out of sync.\n",
    "            mask = np.ones(depths.shape[0], dtype=bool)\n",
    "            mask = np.logical_and(mask, depths > self.min_dist)\n",
    "            mask = np.logical_and(mask, depths < self.max_dist)\n",
    "            mask = np.logical_and(mask, points[0, :] > 1)\n",
    "            mask = np.logical_and(mask, points[0, :] < self.w_nn - 1)\n",
    "            mask = np.logical_and(mask, points[1, :] > 1)\n",
    "            mask = np.logical_and(mask, points[1, :] < self.h_nn - 1)\n",
    "            points = points[:, mask]\n",
    "\n",
    "            # Clip values of points between min_dist and max_dist\n",
    "            #points[2, :] = np.clip(points[2, :], self.min_dist, self.max_dist)\n",
    "            \n",
    "            # Finally, we normalize. We have to apply this normalization in test!\n",
    "            points[2, :] = (points[2, :] - self.min_dist) / (self.max_dist - self.min_dist)\n",
    "            \n",
    "            \n",
    "            # Append radar or lidar pointcloud\n",
    "            if is_radar:\n",
    "                radar_adapted = points\n",
    "                is_radar=False\n",
    "            else:\n",
    "                lidar_adapted = points\n",
    "        \n",
    "        # PREPARE RADAR POINTCLOUD\n",
    "        \n",
    "        # We normalize the radar points to 0-1\n",
    "        radar_adapted[0,:] /= self.w_nn\n",
    "        radar_adapted[1,:] /= self.h_nn\n",
    "        \n",
    "        # Now we resample the radar array to have fixed self.number_radar_points\n",
    "        num_points = radar_adapted.shape[1]\n",
    "        if num_points >= self.number_radar_points:\n",
    "            # If the initial pointcloud has more points, select target_size points without replacement\n",
    "            selected_indices = np.random.choice(num_points, size=self.number_radar_points, replace=False)\n",
    "            radar_adapted = radar_adapted[:, selected_indices]\n",
    "        else:\n",
    "            # If the initial pointcloud has less points, randomly sample with replacement until filling target_size\n",
    "            selected_indices = np.random.choice(num_points, size=self.number_radar_points - num_points, replace=True)\n",
    "            radar_adapted = np.hstack([radar_adapted, radar_adapted[:, selected_indices]])\n",
    "        \n",
    "        # PREPARE LIDAR POINTCLOUD\n",
    "        lidar_matrix = np.zeros((self.h_nn, self.w_nn))\n",
    "        lidar_depths = lidar_adapted[2,:]\n",
    "\n",
    "        # Get indices for matrix\n",
    "        pixel_indices = (lidar_adapted[:2, :]+0.5).astype(int)\n",
    "        lidar_matrix[pixel_indices[1, :], pixel_indices[0, :]] = lidar_depths\n",
    "                \n",
    "        # Return the IDX, the relative depth map, the radar PC and the lidar PC\n",
    "        return self.sample_indices[idx], np.expand_dims(rel_depth, axis=0), radar_adapted, np.expand_dims(lidar_matrix, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c80b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_DATA = '/ssd/Datasets_and_code/nuscenes_depth_estimation/dataset/dataset_radar_cam' # Root to the folder with the prepared data\n",
    "W_RESIZED = 800 # If 0, the image is not resized in width\n",
    "H_RESIZED = 450 # If 0, the image is not resized in height\n",
    "MIN_DIST = 1 # Threshold minimum depth to discard points\n",
    "MAX_DIST = 50 # Threshold maximum depth to discard points\n",
    "NUMBER_RADAR_POINTS = 100 # Number of radar points to use. If the number of points in a sample is less than this, they are \n",
    "                          # resampled randomly to create an array of fixed number of points. This shouldn't hurt the performance\n",
    "AUGMENT_DIST = False\n",
    "AUGMENT_DIST_MAX_SUBTRACT = 10.0\n",
    "AUGMENT_DIST_MIN_SCALE = 0.5\n",
    "\n",
    "train_set = DepthDatasetNuscenes(\"train\", DIR_DATA, W_RESIZED, H_RESIZED, MIN_DIST, MAX_DIST, NUMBER_RADAR_POINTS, \n",
    "                                AUGMENT_DIST, AUGMENT_DIST_MAX_SUBTRACT, AUGMENT_DIST_MIN_SCALE)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdb58df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two ways to get a sample\n",
    "#sample = next(iter(train_loader))\n",
    "sample = train_set.__getitem__(0)\n",
    "print(\"Rel depth shape: \", sample[1].shape)\n",
    "draw_sample(sample, MIN_DIST, MAX_DIST)\n",
    "draw_masked_depth(sample[1], 0.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694204e5-c951-497c-b3f7-8864fd6f3afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: With the nuscenes devkit\n",
    "DIR_NUSCENES = \"/ssd/Datasets_and_code/nuscenes_depth_estimation/dataset/nuscenes_mini\"\n",
    "VERSION = \"v1.0-mini\"\n",
    "idx_to_token = torch.load(os.path.join(DIR_DATA,'idx_to_token.tar'))\n",
    "nusc = NuScenes(version=VERSION, dataroot=DIR_NUSCENES, verbose=True)\n",
    "nusc.render_pointcloud_in_image(idx_to_token[sample[0]], pointsensor_channel='RADAR_FRONT')\n",
    "nusc.render_pointcloud_in_image(idx_to_token[sample[0]], pointsensor_channel='LIDAR_TOP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af0ee5d-5a46-4a92-8d1e-72ca7a591b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
